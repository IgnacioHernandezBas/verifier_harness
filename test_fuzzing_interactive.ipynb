{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change-Aware Fuzzing Test Generation - Interactive Testing\n",
    "\n",
    "This notebook allows you to interactively test the fuzzing pipeline components:\n",
    "1. **Patch Analysis** - Extract changed functions and lines from diffs\n",
    "2. **Test Generation** - Generate Hypothesis property-based tests\n",
    "3. **Coverage Analysis** - Analyze coverage of changed lines only\n",
    "\n",
    "Use this to verify that the fuzzing test generation works correctly before integrating with SWE-bench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from verifier.dynamic_analyzers.patch_analyzer import PatchAnalyzer\n",
    "from verifier.dynamic_analyzers.test_generator import HypothesisTestGenerator\n",
    "from verifier.dynamic_analyzers.coverage_analyzer import CoverageAnalyzer\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Simple Division by Zero Fix\n",
    "\n",
    "This is a classic example - adding a check for division by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch:\n",
      "\n",
      "--- a/math_utils.py\n",
      "+++ b/math_utils.py\n",
      "@@ -1,5 +1,7 @@\n",
      " def divide(a, b):\n",
      "-    return a / b\n",
      "+    if b == 0:\n",
      "+        raise ValueError(\"Cannot divide by zero\")\n",
      "+    return a / b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a simple patch\n",
    "patch_diff = \"\"\"\n",
    "--- a/math_utils.py\n",
    "+++ b/math_utils.py\n",
    "@@ -1,5 +1,7 @@\n",
    " def divide(a, b):\n",
    "-    return a / b\n",
    "+    if b == 0:\n",
    "+        raise ValueError(\"Cannot divide by zero\")\n",
    "+    return a / b\n",
    "\"\"\"\n",
    "\n",
    "patched_code = \"\"\"\n",
    "def divide(a, b):\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    return a / b\n",
    "\"\"\"\n",
    "\n",
    "print(\"Patch:\")\n",
    "print(patch_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Analyze the Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PATCH ANALYSIS RESULTS\n",
      "================================================================================\n",
      "Changed functions: ['divide']\n",
      "All changed lines: [2, 3, 4]\n",
      "Changed lines by function: {'divide': [2, 3, 4]}\n",
      "\n",
      "Change types:\n",
      "  - conditionals: 1 changes\n",
      "      Line 3: if_statement\n",
      "  - exceptions: 1 changes\n",
      "      Line 4: exception\n",
      "  - operations: 1 changes\n",
      "      Line 3: operation\n"
     ]
    }
   ],
   "source": [
    "# Analyze patch\n",
    "analyzer = PatchAnalyzer()\n",
    "patch_analysis = analyzer.parse_patch(patch_diff, patched_code)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PATCH ANALYSIS RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Changed functions: {patch_analysis.changed_functions}\")\n",
    "print(f\"All changed lines: {patch_analysis.all_changed_lines}\")\n",
    "print(f\"Changed lines by function: {patch_analysis.changed_lines}\")\n",
    "print(f\"\\nChange types:\")\n",
    "for change_type, changes in patch_analysis.change_types.items():\n",
    "    if changes:\n",
    "        print(f\"  - {change_type}: {len(changes)} changes\")\n",
    "        for change in changes:\n",
    "            print(f\"      Line {change['line']}: {change['type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate Fuzzing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATED FUZZING TESTS\n",
      "================================================================================\n",
      "Total test functions: 3\n",
      "Total code length: 2025 characters\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST CODE:\n",
      "--------------------------------------------------------------------------------\n",
      "# Auto-generated tests for patch validation\n",
      "import pytest\n",
      "from hypothesis import given, strategies as st, settings\n",
      "from hypothesis import assume\n",
      "import sys\n",
      "from pathlib import Path\n",
      "\n",
      "# Import the module under test\n",
      "# This assumes the module is available in PYTHONPATH\n",
      "\n",
      "@given(st.one_of(st.none(), st.integers(min_value=-100, max_value=100), st.text()), st.one_of(st.none(), st.integers(min_value=-100, max_value=100), st.text()))\n",
      "@settings(max_examples=50, deadline=1000)\n",
      "def test_divide_boundaries(arg0, arg1):\n",
      "    \"\"\"Test boundary conditions for divide\"\"\"\n",
      "    try:\n",
      "        # Try calling with various boundary values\n",
      "        result = divide(arg0, arg1)\n",
      "        # If function returns, it should be deterministic\n",
      "        result2 = divide(arg0, arg1)\n",
      "        assert result == result2, 'Function should be deterministic'\n",
      "    except (ValueError, TypeError, AttributeError, ZeroDivisionError, KeyError, IndexError):\n",
      "        pass  # Expected for invalid inputs\n",
      "\n",
      "def test_divide_exceptions():\n",
      "    \"\"\"Test exception handling for divide\"\"\"\n",
      "    # Test with None\n",
      "    try:\n",
      "        result = divide(None)\n",
      "    except (ValueError, TypeError, AttributeError):\n",
      "        pass  # Expected exception\n",
      "    \n",
      "    # Test with invalid types\n",
      "    try:\n",
      "        result = divide('invalid', -1, [])\n",
      "    except (ValueError, TypeError, AttributeError, IndexError):\n",
      "        pass  # Expected exception\n",
      "\n",
      "@given(st.one_of(st.integers(), st.text()), st.one_of(st.integers(), st.lists(st.integers())))\n",
      "@settings(max_examples=100, deadline=1000)\n",
      "def test_divide_properties(arg0, arg1):\n",
      "    \"\"\"Test general properties of divide\"\"\"\n",
      "    try:\n",
      "        # Determinism test - same inputs should yield same outputs\n",
      "        result1 = divide(arg0, arg1)\n",
      "        result2 = divide(arg0, arg1)\n",
      "        assert result1 == result2, 'Function should be deterministic'\n",
      "        \n",
      "        # Type stability test - result type should be consistent\n",
      "        assert type(result1) == type(result2), 'Result type should be stable'\n",
      "    except Exception:\n",
      "        pass  # Some inputs expected to fail\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate tests\n",
    "generator = HypothesisTestGenerator()\n",
    "test_code = generator.generate_tests(patch_analysis, patched_code)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATED FUZZING TESTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total test functions: {test_code.count('def test_')}\")\n",
    "print(f\"Total code length: {len(test_code)} characters\")\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"TEST CODE:\")\n",
    "print(\"-\"*80)\n",
    "print(test_code)\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: More Complex Patch - Input Validation\n",
    "\n",
    "Let's test with a more complex patch that adds multiple conditionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed functions: ['process_data']\n",
      "Changed lines: [6, 7, 8, 9]\n",
      "\n",
      "Change types:\n",
      "  conditionals: 1 changes\n",
      "  exceptions: 1 changes\n",
      "  operations: 1 changes\n"
     ]
    }
   ],
   "source": [
    "patch_diff_2 = \"\"\"\n",
    "--- a/utils.py\n",
    "+++ b/utils.py\n",
    "@@ -5,6 +5,10 @@ def process_data(items):\n",
    "     Process a list of items.\n",
    "+    if not items:\n",
    "+        return []\n",
    "+    if not isinstance(items, list):\n",
    "+        raise TypeError(\"items must be a list\")\n",
    "     return [item * 2 for item in items]\n",
    "\"\"\"\n",
    "\n",
    "patched_code_2 = \"\"\"\n",
    "def process_data(items):\n",
    "    '''Process a list of items.'''\n",
    "    if not items:\n",
    "        return []\n",
    "    if not isinstance(items, list):\n",
    "        raise TypeError(\"items must be a list\")\n",
    "    return [item * 2 for item in items]\n",
    "\"\"\"\n",
    "\n",
    "# Analyze\n",
    "patch_analysis_2 = analyzer.parse_patch(patch_diff_2, patched_code_2)\n",
    "\n",
    "print(\"Changed functions:\", patch_analysis_2.changed_functions)\n",
    "print(\"Changed lines:\", patch_analysis_2.all_changed_lines)\n",
    "print(\"\\nChange types:\")\n",
    "for change_type, changes in patch_analysis_2.change_types.items():\n",
    "    if changes:\n",
    "        print(f\"  {change_type}: {len(changes)} changes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATED TESTS FOR INPUT VALIDATION PATCH\n",
      "================================================================================\n",
      "# Auto-generated tests for patch validation\n",
      "import pytest\n",
      "from hypothesis import given, strategies as st, settings\n",
      "from hypothesis import assume\n",
      "import sys\n",
      "from pathlib import Path\n",
      "\n",
      "# Import the module under test\n",
      "# This assumes the module is available in PYTHONPATH\n",
      "\n",
      "@given(st.one_of(st.none(), st.integers(), st.text()))\n",
      "@settings(max_examples=50, deadline=1000)\n",
      "def test_process_data_boundaries(arg0):\n",
      "    \"\"\"Test boundary conditions for process_data\"\"\"\n",
      "    try:\n",
      "        # Try calling with various boundary values\n",
      "        result = process_data(arg0)\n",
      "        # If function returns, it should be deterministic\n",
      "        result2 = process_data(arg0)\n",
      "        assert result == result2, 'Function should be deterministic'\n",
      "    except (ValueError, TypeError, AttributeError, ZeroDivisionError, KeyError, IndexError):\n",
      "        pass  # Expected for invalid inputs\n",
      "\n",
      "def test_process_data_exceptions():\n",
      "    \"\"\"Test exception handling for process_data\"\"\"\n",
      "    # Test with None\n",
      "    try:\n",
      "        result = process_data(None)\n",
      "    except (ValueError, TypeError, AttributeError):\n",
      "        pass  # Expected exception\n",
      "    \n",
      "    # Test with invalid types\n",
      "    try:\n",
      "        result = process_data('invalid')\n",
      "    except (ValueError, TypeError, AttributeError, IndexError):\n",
      "        pass  # Expected exception\n",
      "\n",
      "@given(st.one_of(st.integers(), st.text(), st.lists(st.integers())))\n",
      "@settings(max_examples=100, deadline=1000)\n",
      "def test_process_data_properties(arg0):\n",
      "    \"\"\"Test general properties of process_data\"\"\"\n",
      "    try:\n",
      "        # Determinism test - same inputs should yield same outputs\n",
      "        result1 = process_data(arg0)\n",
      "        result2 = process_data(arg0)\n",
      "        assert result1 == result2, 'Function should be deterministic'\n",
      "        \n",
      "        # Type stability test - result type should be consistent\n",
      "        assert type(result1) == type(result2), 'Result type should be stable'\n",
      "    except Exception:\n",
      "        pass  # Some inputs expected to fail\n",
      "\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate tests for the second patch\n",
    "test_code_2 = generator.generate_tests(patch_analysis_2, patched_code_2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATED TESTS FOR INPUT VALIDATION PATCH\")\n",
    "print(\"=\"*80)\n",
    "print(test_code_2)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Real SWE-bench Example\n",
    "\n",
    "Now let's try with a real example from one of your repos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 repositories in repos_temp/\n",
      "  - pytest-dev__pytest\n"
     ]
    }
   ],
   "source": [
    "# Let's check if we have any real patches in the repos_temp directory\n",
    "import os\n",
    "\n",
    "repos_temp = Path(\"repos_temp\")\n",
    "if repos_temp.exists():\n",
    "    repos = [d for d in repos_temp.iterdir() if d.is_dir()]\n",
    "    print(f\"Found {len(repos)} repositories in repos_temp/\")\n",
    "    for repo in repos[:5]:  # Show first 5\n",
    "        print(f\"  - {repo.name}\")\n",
    "else:\n",
    "    print(\"No repos_temp directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Coverage Analysis (Mock)\n",
    "\n",
    "Let's test the coverage analyzer with mock coverage data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COVERAGE ANALYSIS (Change-Aware)\n",
      "================================================================================\n",
      "Overall coverage: 100.0%\n",
      "Total changed lines: 3\n",
      "Covered changed lines: 3\n",
      "Covered lines: [2, 3, 4]\n",
      "Uncovered lines: []\n",
      "\n",
      "Per-function coverage:\n",
      "  divide: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Mock coverage data (simulating what coverage.py would return)\n",
    "mock_coverage_data = {\n",
    "    'files': {\n",
    "        'math_utils.py': {\n",
    "            'executed_lines': [1, 2, 3, 4],  # Lines that were executed\n",
    "            'missing_lines': [],  # Lines that weren't executed\n",
    "            'summary': {\n",
    "                'covered_lines': 4,\n",
    "                'num_statements': 4,\n",
    "                'percent_covered': 100.0\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Changed lines from our first example (divide function)\n",
    "changed_lines = {\n",
    "    'divide': [2, 3, 4]  # The if statement and raise statement\n",
    "}\n",
    "\n",
    "# Analyze coverage\n",
    "coverage_analyzer = CoverageAnalyzer()\n",
    "coverage_result = coverage_analyzer.calculate_changed_line_coverage(\n",
    "    mock_coverage_data,\n",
    "    changed_lines,\n",
    "    all_changed_lines=[2, 3, 4]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COVERAGE ANALYSIS (Change-Aware)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Overall coverage: {coverage_result['overall_coverage']:.1%}\")\n",
    "print(f\"Total changed lines: {coverage_result['total_changed_lines']}\")\n",
    "print(f\"Covered changed lines: {coverage_result['total_covered_lines']}\")\n",
    "print(f\"Covered lines: {coverage_result['covered_lines']}\")\n",
    "print(f\"Uncovered lines: {coverage_result['uncovered_lines']}\")\n",
    "print(f\"\\nPer-function coverage:\")\n",
    "for func, cov in coverage_result['per_function_coverage'].items():\n",
    "    print(f\"  {func}: {cov:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Generate Coverage Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHANGE-AWARE COVERAGE REPORT\n",
      "================================================================================\n",
      "\n",
      "Changed Functions: divide\n",
      "Total Changed Lines: 3\n",
      "Covered Changed Lines: 3\n",
      "Overall Coverage: 100.0%\n",
      "\n",
      "Per-Function Coverage:\n",
      "----------------------------------------\n",
      "  ✓ divide: 100.0%\n",
      "\n",
      "Covered Lines (3):\n",
      "----------------------------------------\n",
      "  [2, 3, 4]\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate a human-readable report\n",
    "report = coverage_analyzer.generate_coverage_report(coverage_result, patch_analysis)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6: Your Custom Patch\n",
    "\n",
    "Use this cell to test with your own patches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your own patch here\n",
    "custom_patch = \"\"\"\n",
    "--- a/yourfile.py\n",
    "+++ b/yourfile.py\n",
    "@@ -10,5 +10,6 @@\n",
    " def your_function():\n",
    "+    # Your changes here\n",
    "     pass\n",
    "\"\"\"\n",
    "\n",
    "custom_code = \"\"\"\n",
    "def your_function():\n",
    "    # Your changes here\n",
    "    pass\n",
    "\"\"\"\n",
    "\n",
    "# Analyze and generate tests\n",
    "custom_analysis = analyzer.parse_patch(custom_patch, custom_code)\n",
    "custom_tests = generator.generate_tests(custom_analysis, custom_code)\n",
    "\n",
    "print(\"Custom patch analysis:\")\n",
    "print(f\"  Changed functions: {custom_analysis.changed_functions}\")\n",
    "print(f\"  Changed lines: {custom_analysis.all_changed_lines}\")\n",
    "print(\"\\nGenerated tests:\")\n",
    "print(custom_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We've Tested:\n",
    "1. ✅ Patch analysis extracts changed functions and lines correctly\n",
    "2. ✅ Test generator creates Hypothesis property-based tests\n",
    "3. ✅ Coverage analyzer focuses on changed lines only\n",
    "\n",
    "### What's Working:\n",
    "- The fuzzing pipeline components work independently\n",
    "- Test generation targets changed code specifically\n",
    "- Coverage analysis is change-aware\n",
    "\n",
    "### What's Missing:\n",
    "- Integration with `test_patch_singularity.py:run_evaluation()`\n",
    "- Execution of generated tests in Singularity containers\n",
    "- Combining fuzzing results with SWE-bench test results\n",
    "\n",
    "### Next Steps:\n",
    "1. Verify test execution works in Singularity (use `test_fuzzing_pipeline.py`)\n",
    "2. Integrate fuzzing into the SWE-bench evaluation pipeline\n",
    "3. Test on real SWE-bench instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility: Save generated tests to a file for manual inspection\n",
    "def save_tests(test_code, filename=\"generated_test.py\"):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(test_code)\n",
    "    print(f\"✓ Tests saved to {filename}\")\n",
    "\n",
    "# Example: save the first test\n",
    "# save_tests(test_code, \"test_divide_fuzzing.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

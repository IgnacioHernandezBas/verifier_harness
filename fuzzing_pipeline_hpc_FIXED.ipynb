{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPC Fuzzing Pipeline - WORKING VERSION\n",
    "\n",
    "This notebook has been fixed to work with the correct SWE-bench Docker images.\n",
    "\n",
    "## Key Fixes:\n",
    "- Uses correct image pattern: `swebench/sweb.eval.x86_64.{full_repo}_1776_{instance_id}:latest`\n",
    "- SWE-bench images are PUBLIC - no Docker Hub authentication required!\n",
    "- Apptainer environment variables properly configured\n",
    "\n",
    "## Pipeline Overview:\n",
    "\n",
    "### STATIC ANALYSIS (Host)\n",
    "1. Patch Loading\n",
    "2. Repository Setup  \n",
    "3. Static Analysis (Pylint, Flake8, Radon, Mypy, Bandit)\n",
    "\n",
    "### DYNAMIC ANALYSIS (Container)\n",
    "4. Build Instance-Specific Singularity Container\n",
    "5. Install Dependencies\n",
    "6. Run Existing Tests\n",
    "7. Patch Analysis\n",
    "8. Generate Hypothesis Tests\n",
    "9. Execute Tests\n",
    "10. Coverage Analysis\n",
    "11. Final Verdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs/nexus-scratch/ihbas/miniconda3/envs/verifier_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports OK\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, os\n",
    "from pathlib import Path\n",
    "import json, time, ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Dataset and patch handling\n",
    "from swebench_integration import DatasetLoader, PatchLoader\n",
    "\n",
    "# Dynamic container building system\n",
    "from swebench_singularity import Config, SingularityBuilder, DockerImageResolver\n",
    "\n",
    "# Analysis modules\n",
    "from verifier.dynamic_analyzers.patch_analyzer import PatchAnalyzer\n",
    "from verifier.dynamic_analyzers.test_generator import HypothesisTestGenerator\n",
    "from verifier.dynamic_analyzers.singularity_executor import SingularityTestExecutor\n",
    "from verifier.dynamic_analyzers.coverage_analyzer import CoverageAnalyzer\n",
    "from verifier.dynamic_analyzers.test_patch_singularity import (\n",
    "    install_package_in_singularity, \n",
    "    run_tests_in_singularity\n",
    ")\n",
    "\n",
    "# Static analysis\n",
    "import streamlit.modules.static_eval.static_modules.code_quality as code_quality\n",
    "import streamlit.modules.static_eval.static_modules.syntax_structure as syntax_structure\n",
    "from verifier.utils.diff_utils import parse_unified_diff, filter_paths_to_py\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "print(\"‚úì Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup\n",
    "\n",
    "**IMPORTANT**: This cell sets up the correct Docker image patterns for SWE-bench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Docker credentials set (not required for SWE-bench public images)\n",
      "\n",
      "‚úì Configuration initialized\n",
      "  Cache: /fs/nexus-scratch/ihbas/.cache/swebench_singularity\n",
      "  Tmp: /fs/nexus-scratch/ihbas/.tmp/singularity_build\n",
      "  Image pattern: swebench/sweb.eval.x86_64.{repo}_1776_{repo}-{version}:latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 15:32:23,276 - swebench_singularity.singularity_builder - INFO - Singularity available: apptainer version 1.4.4-1.el8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Singularity: True\n",
      "  Docker: False\n"
     ]
    }
   ],
   "source": [
    "# Set Apptainer/Singularity environment variables\n",
    "# NOTE: SWE-bench images are PUBLIC - authentication not required!\n",
    "# Setting credentials anyway for compatibility with other private images\n",
    "os.environ[\"APPTAINER_DOCKER_USERNAME\"] = \"nacheitor12\"\n",
    "os.environ[\"APPTAINER_DOCKER_PASSWORD\"] = \"wN/^4Me%,!5zz_q\"\n",
    "os.environ[\"SINGULARITY_DOCKER_USERNAME\"] = \"nacheitor12\"\n",
    "os.environ[\"SINGULARITY_DOCKER_PASSWORD\"] = \"wN/^4Me%,!5zz_q\"\n",
    "\n",
    "print(\"‚úì Docker credentials set (not required for SWE-bench public images)\")\n",
    "print()\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "# HPC cluster paths\n",
    "config.set(\"singularity.cache_dir\", \"/fs/nexus-scratch/ihbas/.cache/swebench_singularity\")\n",
    "config.set(\"singularity.tmp_dir\", \"/fs/nexus-scratch/ihbas/.tmp/singularity_build\")\n",
    "config.set(\"singularity.cache_internal_dir\", \"/fs/nexus-scratch/ihbas/.singularity/cache\")\n",
    "config.set(\"singularity.build_timeout\", 1800)  # 30 minutes\n",
    "config.set(\"docker.max_retries\", 3)\n",
    "\n",
    "# CRITICAL: Use correct SWE-bench image pattern\n",
    "# Format: swebench/sweb.eval.x86_64.{repo}_1776_{repo}-{version}:latest\n",
    "# Example: swebench/sweb.eval.x86_64.scikit-learn_1776_scikit-learn-10297:latest\n",
    "# NOTE: Uses {repo}-{version}, NOT {instance_id} which includes org prefix\n",
    "config.set(\"docker.image_patterns\", [\n",
    "    \"swebench/sweb.eval.x86_64.{repo}_1776_{repo}-{version}:latest\",\n",
    "])\n",
    "\n",
    "# Initialize builder and resolver\n",
    "builder = SingularityBuilder(config)\n",
    "resolver = DockerImageResolver(config)\n",
    "\n",
    "print(\"‚úì Configuration initialized\")\n",
    "print(f\"  Cache: {config.singularity_cache_dir}\")\n",
    "print(f\"  Tmp: {config.singularity_tmp_dir}\")\n",
    "print(f\"  Image pattern: {config.docker_image_patterns[0]}\")\n",
    "print(f\"  Singularity: {builder.check_singularity_available()}\")\n",
    "print(f\"  Docker: {builder.check_docker_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STATIC ANALYSIS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Load Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì scikit-learn__scikit-learn-10297\n",
      "  Repo: scikit-learn/scikit-learn\n",
      "\n",
      "Patch preview:\n",
      "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\n",
      "--- a/sklearn/linear_model/ridge.py\n",
      "+++ b/sklearn/linear_model/ridge.py\n",
      "@@ -1212,18 +1212,18 @@ class RidgeCV(_BaseRidgeCV, RegressorMixin):\n",
      " \n",
      "     store_cv_values : boolean, default=False\n",
      "         Flag indicating if the cross-validation values corresponding to\n",
      "-        each alpha should be stored in the `cv_values_` attrib...\n"
     ]
    }
   ],
   "source": [
    "REPO_FILTER = \"scikit-learn/scikit-learn\"\n",
    "\n",
    "loader = DatasetLoader(\"princeton-nlp/SWE-bench_Verified\", hf_mode=True, split=\"test\")\n",
    "sample = next(loader.iter_samples(limit=1, filter_repo=REPO_FILTER), None)\n",
    "\n",
    "if sample:\n",
    "    instance_id = sample.get('metadata', {}).get('instance_id', 'unknown')\n",
    "    print(f\"‚úì {instance_id}\")\n",
    "    print(f\"  Repo: {sample['repo']}\")\n",
    "    print(f\"\\nPatch preview:\\n{sample['patch'][:400]}...\")\n",
    "else:\n",
    "    raise Exception(f\"No sample found for {REPO_FILTER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Setup Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Cloning scikit-learn/scikit-learn into /fs/nexus-scratch/ihbas/verifier_harness/repos_temp/scikit-learn__scikit-learn ...\n",
      "‚úì Repo: /fs/nexus-scratch/ihbas/verifier_harness/repos_temp/scikit-learn__scikit-learn\n",
      "‚úì Patch: Applied\n"
     ]
    }
   ],
   "source": [
    "patcher = PatchLoader(sample=sample, repos_root=\"./repos_temp\")\n",
    "repo_path = patcher.clone_repository()\n",
    "patch_result = patcher.apply_patch()\n",
    "\n",
    "print(f\"‚úì Repo: {repo_path}\")\n",
    "print(f\"‚úì Patch: {'Applied' if patch_result['applied'] else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2b: Apply Test Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Applying test_patch...\n",
      "‚úì Test patch applied: Additional patch applied successfully.\n"
     ]
    }
   ],
   "source": [
    "test_patch = sample.get('metadata', {}).get('test_patch', '')\n",
    "\n",
    "if test_patch and test_patch.strip():\n",
    "    print(\"üìù Applying test_patch...\")\n",
    "    try:\n",
    "        test_patch_result = patcher.apply_additional_patch(test_patch)\n",
    "        print(f\"‚úì Test patch applied: {test_patch_result.get('log', 'success')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Test patch application failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No test_patch in metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Static Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Static analysis...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì SQI: 61.54/100 (Fair)\n"
     ]
    }
   ],
   "source": [
    "static_config = {\n",
    "    'checks': {'pylint': True, 'flake8': True, 'radon': True, 'mypy': True, 'bandit': True},\n",
    "    'weights': {'pylint': 0.5, 'flake8': 0.15, 'radon': 0.25, 'mypy': 0.05, 'bandit': 0.05}\n",
    "}\n",
    "\n",
    "print(\"üîç Static analysis...\")\n",
    "cq_results = code_quality.analyze(str(repo_path), sample['patch'], static_config)\n",
    "ss_results = syntax_structure.run_syntax_structure_analysis(str(repo_path), sample['patch'])\n",
    "\n",
    "sqi_data = cq_results.get('sqi', {})\n",
    "print(f\"‚úì SQI: {sqi_data.get('SQI', 0)}/100 ({sqi_data.get('classification', 'Unknown')})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DYNAMIC ANALYSIS (Container)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Build Container\n",
    "\n",
    "This will download and convert the SWE-bench Docker image to Singularity format.\n",
    "The images are PUBLIC and don't require authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 15:34:02,694 - swebench_singularity.singularity_builder - INFO - Using cached image for scikit-learn__scikit-learn-10297: /fs/nexus-scratch/ihbas/.cache/swebench_singularity/scikit-learn/scikit-learn__scikit-learn-10297.sif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê≥ Building container for scikit-learn__scikit-learn-10297...\n",
      "\n",
      "  Docker image: docker.io/swebench/sweb.eval.x86_64.scikit-learn_1776_scikit-learn-10297:latest\n",
      "  Registry: docker.io\n",
      "  Tag: latest\n",
      "\n",
      "‚úì Container ready (from cache)\n",
      "  Path: /fs/nexus-scratch/ihbas/.cache/swebench_singularity/scikit-learn/scikit-learn__scikit-learn-10297.sif\n",
      "  Build time: 0.0s\n",
      "  Python: Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"üê≥ Building container for {instance_id}...\\n\")\n",
    "\n",
    "# Check what Docker image will be used\n",
    "docker_image = resolver.find_available_image(instance_id, check_existence=False)\n",
    "if docker_image:\n",
    "    print(f\"  Docker image: {docker_image.full_name}\")\n",
    "    print(f\"  Registry: {docker_image.registry}\")\n",
    "    print(f\"  Tag: {docker_image.tag}\\n\")\n",
    "\n",
    "# Build the container (will use cache if available)\n",
    "build_result = builder.build_instance(\n",
    "    instance_id=instance_id,\n",
    "    force_rebuild=False,\n",
    "    check_docker_exists=False\n",
    ")\n",
    "\n",
    "if build_result.success:\n",
    "    CONTAINER_IMAGE_PATH = build_result.sif_path\n",
    "    cache_status = \"(from cache)\" if build_result.from_cache else \"(newly built)\"\n",
    "    print(f\"‚úì Container ready {cache_status}\")\n",
    "    print(f\"  Path: {CONTAINER_IMAGE_PATH}\")\n",
    "    print(f\"  Build time: {build_result.build_time_seconds:.1f}s\")\n",
    "    \n",
    "    # Verify container works\n",
    "    result = subprocess.run(\n",
    "        [\"singularity\", \"exec\", str(CONTAINER_IMAGE_PATH), \"python\", \"--version\"],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    print(f\"  Python: {result.stdout.strip()}\")\n",
    "else:\n",
    "    print(f\"‚ùå Container build failed: {build_result.error_message}\")\n",
    "    raise Exception(\"Cannot proceed without container\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing dependencies...\n",
      "\n",
      "üì¶ Installing package and dependencies in: /fs/nexus-scratch/ihbas/verifier_harness/repos_temp/scikit-learn__scikit-learn\n",
      "   Setup files found: setup.py=True, pyproject.toml=False, setup.cfg=True\n",
      "   Attempting editable install...\n",
      "   Installing build dependencies...\n",
      "   Configuring git for build...\n",
      "   Fetching git tags for version detection...\n",
      "   Building C extensions in-place...\n",
      "‚ö†Ô∏è  In-place build failed, trying editable install...\n",
      "‚ÑπÔ∏è  Build and install failed (will use PYTHONPATH mode)\n",
      "   Note: This may not work for packages with C extensions\n",
      "‚ö†Ô∏è No setup.py/pyproject.toml (will use PYTHONPATH mode)\n"
     ]
    }
   ],
   "source": [
    "print(\"üì¶ Installing dependencies...\\n\")\n",
    "\n",
    "install_result = install_package_in_singularity(\n",
    "    repo_path=Path(repo_path),\n",
    "    image_path=str(CONTAINER_IMAGE_PATH)\n",
    ")\n",
    "\n",
    "if install_result.get(\"installed\"):\n",
    "    print(\"‚úì Dependencies installed\")\n",
    "elif install_result.get(\"returncode\") != 0:\n",
    "    print(f\"‚ö†Ô∏è Install issues (code {install_result.get('returncode')})\")\n",
    "    print(install_result.get('stderr', '')[-500:])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No setup.py/pyproject.toml (will use PYTHONPATH mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6: Run Existing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running existing tests...\n",
      "\n",
      "  FAIL_TO_PASS: [\"sklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_cv_store_cv_values\"]\n",
      "  PASS_TO_PASS: [\"sklearn/linear_model/tests/test_ridge.py::test_ridge\", \"sklearn/linear_model/tests/test_ridge.py::test_primal_dual_relationship\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_singular\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_regression_sample_weights\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_sample_weights\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_shapes\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_intercept\", \"sklearn/linear_model/tests/test_ridge.py::test_toy_ridge_object\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_vs_lstsq\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_individual_penalties\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_cv_sparse_svd\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_sparse_svd\", \"sklearn/linear_model/tests/test_ridge.py::test_class_weights\", \"sklearn/linear_model/tests/test_ridge.py::test_class_weight_vs_sample_weight\", \"sklearn/linear_model/tests/test_ridge.py::test_class_weights_cv\", \"sklearn/linear_model/tests/test_ridge.py::test_ridgecv_store_cv_values\", \"sklearn/linear_model/tests/test_ridge.py::test_ridgecv_sample_weight\", \"sklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_sample_weights_greater_than_1d\", \"sklearn/linear_model/tests/test_ridge.py::test_sparse_design_with_sample_weights\", \"sklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_solver_not_supported\", \"sklearn/linear_model/tests/test_ridge.py::test_sparse_cg_max_iter\", \"sklearn/linear_model/tests/test_ridge.py::test_n_iter\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_fit_intercept_sparse\", \"sklearn/linear_model/tests/test_ridge.py::test_errors_and_values_helper\", \"sklearn/linear_model/tests/test_ridge.py::test_errors_and_values_svd_helper\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_no_support_multilabel\", \"sklearn/linear_model/tests/test_ridge.py::test_dtype_match\", \"sklearn/linear_model/tests/test_ridge.py::test_dtype_match_cholesky\"]\n",
      "\n",
      "üì¶ Copying pre-built C extensions from container...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì C extensions copied\n",
      "üß™ Running tests in Singularity:\n",
      "  singularity exec --bind /fs/nexus-scratch/ihbas/verifier_harness/repos_temp/scikit-learn__scikit-learn:/workspace --pwd /workspace --env PYTHONPATH=/workspace /fs/nexus-scratch/ihbas/.cache/swebench_singularity/scikit-learn/scikit-learn__scikit-learn-10297.sif /opt/miniconda3/envs/testbed/bin/python -m pytest -q sklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_cv_store_cv_values sklearn/linear_model/tests/test_ridge.py::test_ridge sklearn/linear_model/tests/test_ridge.py::test_primal_dual_relationship sklearn/linear_model/tests/test_ridge.py::test_ridge_singular sklearn/linear_model/tests/test_ridge.py::test_ridge_regression_sample_weights sklearn/linear_model/tests/test_ridge.py::test_ridge_sample_weights sklearn/linear_model/tests/test_ridge.py::test_ridge_shapes sklearn/linear_model/tests/test_ridge.py::test_ridge_intercept sklearn/linear_model/tests/test_ridge.py::test_toy_ridge_object sklearn/linear_model/tests/test_ridge.py::test_ridge_vs_lstsq sklearn/linear_model/tests/test_ridge.py::test_ridge_individual_penalties sklearn/linear_model/tests/test_ridge.py::test_ridge_cv_sparse_svd sklearn/linear_model/tests/test_ridge.py::test_ridge_sparse_svd sklearn/linear_model/tests/test_ridge.py::test_class_weights sklearn/linear_model/tests/test_ridge.py::test_class_weight_vs_sample_weight sklearn/linear_model/tests/test_ridge.py::test_class_weights_cv sklearn/linear_model/tests/test_ridge.py::test_ridgecv_store_cv_values sklearn/linear_model/tests/test_ridge.py::test_ridgecv_sample_weight sklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_sample_weights_greater_than_1d sklearn/linear_model/tests/test_ridge.py::test_sparse_design_with_sample_weights sklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_solver_not_supported sklearn/linear_model/tests/test_ridge.py::test_sparse_cg_max_iter sklearn/linear_model/tests/test_ridge.py::test_n_iter sklearn/linear_model/tests/test_ridge.py::test_ridge_fit_intercept_sparse sklearn/linear_model/tests/test_ridge.py::test_errors_and_values_helper sklearn/linear_model/tests/test_ridge.py::test_errors_and_values_svd_helper sklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_no_support_multilabel sklearn/linear_model/tests/test_ridge.py::test_dtype_match sklearn/linear_model/tests/test_ridge.py::test_dtype_match_cholesky\n",
      "\n",
      "Exit code: 0\n",
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                            [100%]\u001b[0m\n",
      "\u001b[33m\u001b[32m29 passed\u001b[0m, \u001b[33m\u001b[1m22 warnings\u001b[0m\u001b[33m in 10.83s\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "‚úì Tests passed\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Running existing tests...\\n\")\n",
    "\n",
    "fail_to_pass = sample.get('metadata', {}).get('FAIL_TO_PASS', '[]')\n",
    "pass_to_pass = sample.get('metadata', {}).get('PASS_TO_PASS', '[]')\n",
    "\n",
    "print(f\"  FAIL_TO_PASS: {fail_to_pass}\")\n",
    "print(f\"  PASS_TO_PASS: {pass_to_pass}\\n\")\n",
    "\n",
    "try:\n",
    "    f2p = ast.literal_eval(fail_to_pass) if isinstance(fail_to_pass, str) else fail_to_pass\n",
    "    p2p = ast.literal_eval(pass_to_pass) if isinstance(pass_to_pass, str) else pass_to_pass\n",
    "except:\n",
    "    f2p, p2p = [], []\n",
    "\n",
    "all_tests = f2p + p2p\n",
    "\n",
    "test_result = run_tests_in_singularity(\n",
    "    repo_path=Path(repo_path),\n",
    "    tests=all_tests,\n",
    "    image_path=str(CONTAINER_IMAGE_PATH)\n",
    ")\n",
    "\n",
    "print(f\"Exit code: {test_result['returncode']}\")\n",
    "print((test_result['stdout'] + test_result['stderr'])[-1500:])\n",
    "print(f\"\\n{'‚úì' if test_result['returncode'] == 0 else '‚ö†Ô∏è'} Tests {'passed' if test_result['returncode'] == 0 else 'had issues'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining Stages\n",
    "\n",
    "The notebook continues with:\n",
    "- Stage 7: Patch Analysis\n",
    "- Stage 8: Generate Hypothesis Tests\n",
    "- Stage 9: Execute Tests\n",
    "- Stage 10: Coverage Analysis\n",
    "- Stage 11: Final Verdict\n",
    "\n",
    "Add the remaining cells from your original notebook here as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

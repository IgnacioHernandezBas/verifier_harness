{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Fuzzing Pipeline Analysis\n",
    "\n",
    "Comprehensive analysis from patch arrival to test execution.\n",
    "\n",
    "## Pipeline Overview:\n",
    "\n",
    "### STATIC ANALYSIS (Host)\n",
    "1. Patch Loading\n",
    "2. Repository Setup  \n",
    "3. Static Analysis (Pylint, Flake8, Radon, Mypy, Bandit)\n",
    "\n",
    "### DYNAMIC ANALYSIS (Container)\n",
    "4. Build Singularity Container\n",
    "5. Install Dependencies\n",
    "6. Run Existing Tests\n",
    "7. Patch Analysis\n",
    "8. Generate Hypothesis Tests\n",
    "9. Execute Tests\n",
    "10. Coverage Analysis\n",
    "11. Final Verdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports OK\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "from pathlib import Path\n",
    "import json, time, ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from swebench_integration import DatasetLoader, PatchLoader\n",
    "from verifier.dynamic_analyzers.patch_analyzer import PatchAnalyzer\n",
    "from verifier.dynamic_analyzers.test_generator import HypothesisTestGenerator\n",
    "from verifier.dynamic_analyzers.singularity_executor import SingularityTestExecutor\n",
    "from verifier.dynamic_analyzers.coverage_analyzer import CoverageAnalyzer\n",
    "from verifier.dynamic_analyzers.test_patch_singularity import build_singularity_image, install_package_in_singularity, run_tests_in_singularity\n",
    "import streamlit.modules.static_eval.static_modules.code_quality as code_quality\n",
    "import streamlit.modules.static_eval.static_modules.syntax_structure as syntax_structure\n",
    "from verifier.utils.diff_utils import parse_unified_diff, filter_paths_to_py\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "print(\"‚úì Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STATIC ANALYSIS\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Load Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì scikit-learn__scikit-learn-10297\n",
      "  Repo: scikit-learn/scikit-learn\n",
      "\n",
      "Patch preview:\n",
      "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\n",
      "--- a/sklearn/linear_model/ridge.py\n",
      "+++ b/sklearn/linear_model/ridge.py\n",
      "@@ -1212,18 +1212,18 @@ class RidgeCV(_BaseRidgeCV, RegressorMixin):\n",
      " \n",
      "     store_cv_values : boolean, default=False\n",
      "         Flag indicating if the cross-validation values corresponding to\n",
      "-        each alpha should be stored in the `cv_values_` attrib...\n"
     ]
    }
   ],
   "source": [
    "REPO_FILTER = \"scikit-learn/scikit-learn\" # Example: pytest-dev/pytest, pylint-dev/pylint\n",
    "\n",
    "loader = DatasetLoader(\"princeton-nlp/SWE-bench_Verified\", hf_mode=True, split=\"test\")\n",
    "sample = next(loader.iter_samples(limit=1, filter_repo=REPO_FILTER), None)\n",
    "\n",
    "if sample:\n",
    "    print(f\"‚úì {sample.get('metadata', {}).get('instance_id', 'unknown')}\")\n",
    "    print(f\"  Repo: {sample['repo']}\")\n",
    "    print(f\"\\nPatch preview:\\n{sample['patch'][:400]}...\")\n",
    "else:\n",
    "    raise Exception(f\"No sample found for {REPO_FILTER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Setup Repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Cloning scikit-learn/scikit-learn into /fs/nexus-scratch/ihbas/verifier_harness/repos_temp/scikit-learn__scikit-learn ...\n",
      "‚úì Repo: /fs/nexus-scratch/ihbas/verifier_harness/repos_temp/scikit-learn__scikit-learn\n",
      "‚úì Patch: Applied\n"
     ]
    }
   ],
   "source": [
    "patcher = PatchLoader(sample=sample, repos_root=\"./repos_temp\")\n",
    "repo_path = patcher.clone_repository()\n",
    "patch_result = patcher.apply_patch()\n",
    "\n",
    "print(f\"‚úì Repo: {repo_path}\")\n",
    "print(f\"‚úì Patch: {'Applied' if patch_result['applied'] else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2b: Apply Test Patch (if exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Applying test_patch...\n",
      "‚úì Test patch applied: Additional patch applied successfully.\n"
     ]
    }
   ],
   "source": [
    "# In SWE-bench, test_patch contains additional tests needed to validate the fix\n",
    "# These tests (like test_clear_for_call_stage) don't exist until we apply the test_patch\n",
    "test_patch = sample.get('metadata', {}).get('test_patch', '')\n",
    "\n",
    "if test_patch and test_patch.strip():\n",
    "    print(\"üìù Applying test_patch...\")\n",
    "    try:\n",
    "        test_patch_result = patcher.apply_additional_patch(test_patch)\n",
    "        print(f\"‚úì Test patch applied: {test_patch_result.get('log', 'success')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Test patch application failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No test_patch in metadata (tests already exist in repo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Static Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Static analysis...\n",
      "‚úì SQI: 61.54/100 (Fair)\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'checks': {'pylint': True, 'flake8': True, 'radon': True, 'mypy': True, 'bandit': True},\n",
    "    'weights': {'pylint': 0.5, 'flake8': 0.15, 'radon': 0.25, 'mypy': 0.05, 'bandit': 0.05}\n",
    "}\n",
    "\n",
    "print(\"üîç Static analysis...\")\n",
    "cq_results = code_quality.analyze(str(repo_path), sample['patch'], config)\n",
    "ss_results = syntax_structure.run_syntax_structure_analysis(str(repo_path), sample['patch'])\n",
    "\n",
    "sqi_data = cq_results.get('sqi', {})\n",
    "print(f\"‚úì SQI: {sqi_data.get('SQI', 0)}/100 ({sqi_data.get('classification', 'Unknown')})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DYNAMIC ANALYSIS (Container)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Build Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê≥ Building container...\n",
      "‚úÖ Singularity image already exists: /fs/nexus-scratch/ihbas/.containers/singularity/verifier-swebench.sif\n",
      "‚úì Container: /fs/nexus-scratch/ihbas/.containers/singularity/verifier-swebench.sif\n",
      "  Python 3.11.14\n"
     ]
    }
   ],
   "source": [
    "CONTAINER_IMAGE_PATH = \"/fs/nexus-scratch/ihbas/.containers/singularity/verifier-swebench.sif\"\n",
    "PYTHON_VERSION = \"3.11\"\n",
    "\n",
    "print(\"üê≥ Building container...\")\n",
    "image_path = build_singularity_image(CONTAINER_IMAGE_PATH, PYTHON_VERSION, force_rebuild=False)\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"singularity\", \"exec\", str(image_path), \"python\", \"--version\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(f\"‚úì Container: {image_path}\")\n",
    "print(f\"  {result.stdout.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing dependencies...\n",
      "üì¶ Installing package and dependencies in: /fs/nexus-scratch/ihbas/verifier_harness/repos_temp/scikit-learn__scikit-learn\n",
      "   Setup files found: setup.py=True, pyproject.toml=False, setup.cfg=True\n",
      "   Attempting editable install...\n",
      "   Installing build dependencies...\n",
      "   Configuring git for build...\n",
      "   Fetching git tags for version detection...\n",
      "‚ÑπÔ∏è  Editable install not possible (will use PYTHONPATH mode)\n",
      "   This is normal for packages with C extensions or complex build requirements\n",
      "‚ö†Ô∏è No setup.py/pyproject.toml\n"
     ]
    }
   ],
   "source": [
    "print(\"üì¶ Installing dependencies...\")\n",
    "\n",
    "install_result = install_package_in_singularity(\n",
    "    repo_path=Path(repo_path),\n",
    "    image_path=CONTAINER_IMAGE_PATH\n",
    ")\n",
    "\n",
    "if install_result.get(\"installed\"):\n",
    "    print(\"‚úì Dependencies installed\")\n",
    "elif install_result.get(\"returncode\") != 0:\n",
    "    print(f\"‚ö†Ô∏è Install issues (code {install_result.get('returncode')})\")\n",
    "    print(install_result.get('stderr', '')[-500:])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No setup.py/pyproject.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6: Run Existing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running existing tests...\n",
      "\n",
      "  FAIL_TO_PASS: [\"sklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_cv_store_cv_values\"]\n",
      "  PASS_TO_PASS: [\"sklearn/linear_model/tests/test_ridge.py::test_ridge\", \"sklearn/linear_model/tests/test_ridge.py::test_primal_dual_relationship\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_singular\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_regression_sample_weights\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_sample_weights\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_shapes\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_intercept\", \"sklearn/linear_model/tests/test_ridge.py::test_toy_ridge_object\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_vs_lstsq\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_individual_penalties\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_cv_sparse_svd\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_sparse_svd\", \"sklearn/linear_model/tests/test_ridge.py::test_class_weights\", \"sklearn/linear_model/tests/test_ridge.py::test_class_weight_vs_sample_weight\", \"sklearn/linear_model/tests/test_ridge.py::test_class_weights_cv\", \"sklearn/linear_model/tests/test_ridge.py::test_ridgecv_store_cv_values\", \"sklearn/linear_model/tests/test_ridge.py::test_ridgecv_sample_weight\", \"sklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_sample_weights_greater_than_1d\", \"sklearn/linear_model/tests/test_ridge.py::test_sparse_design_with_sample_weights\", \"sklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_solver_not_supported\", \"sklearn/linear_model/tests/test_ridge.py::test_sparse_cg_max_iter\", \"sklearn/linear_model/tests/test_ridge.py::test_n_iter\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_fit_intercept_sparse\", \"sklearn/linear_model/tests/test_ridge.py::test_errors_and_values_helper\", \"sklearn/linear_model/tests/test_ridge.py::test_errors_and_values_svd_helper\", \"sklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_no_support_multilabel\", \"sklearn/linear_model/tests/test_ridge.py::test_dtype_match\", \"sklearn/linear_model/tests/test_ridge.py::test_dtype_match_cholesky\"]\n",
      "\n",
      "üß™ Running tests in Singularity:\n",
      "  singularity exec --fakeroot --bind /fs/nexus-scratch/ihbas/verifier_harness/repos_temp/scikit-learn__scikit-learn:/workspace --bind /fs/nexus-scratch/ihbas/.local:/pip_install_base --pwd /workspace --env PYTHONPATH=/workspace --env PYTHONUSERBASE=/pip_install_base /fs/nexus-scratch/ihbas/.containers/singularity/verifier-swebench.sif pytest -q sklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_cv_store_cv_values sklearn/linear_model/tests/test_ridge.py::test_ridge sklearn/linear_model/tests/test_ridge.py::test_primal_dual_relationship sklearn/linear_model/tests/test_ridge.py::test_ridge_singular sklearn/linear_model/tests/test_ridge.py::test_ridge_regression_sample_weights sklearn/linear_model/tests/test_ridge.py::test_ridge_sample_weights sklearn/linear_model/tests/test_ridge.py::test_ridge_shapes sklearn/linear_model/tests/test_ridge.py::test_ridge_intercept sklearn/linear_model/tests/test_ridge.py::test_toy_ridge_object sklearn/linear_model/tests/test_ridge.py::test_ridge_vs_lstsq sklearn/linear_model/tests/test_ridge.py::test_ridge_individual_penalties sklearn/linear_model/tests/test_ridge.py::test_ridge_cv_sparse_svd sklearn/linear_model/tests/test_ridge.py::test_ridge_sparse_svd sklearn/linear_model/tests/test_ridge.py::test_class_weights sklearn/linear_model/tests/test_ridge.py::test_class_weight_vs_sample_weight sklearn/linear_model/tests/test_ridge.py::test_class_weights_cv sklearn/linear_model/tests/test_ridge.py::test_ridgecv_store_cv_values sklearn/linear_model/tests/test_ridge.py::test_ridgecv_sample_weight sklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_sample_weights_greater_than_1d sklearn/linear_model/tests/test_ridge.py::test_sparse_design_with_sample_weights sklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_solver_not_supported sklearn/linear_model/tests/test_ridge.py::test_sparse_cg_max_iter sklearn/linear_model/tests/test_ridge.py::test_n_iter sklearn/linear_model/tests/test_ridge.py::test_ridge_fit_intercept_sparse sklearn/linear_model/tests/test_ridge.py::test_errors_and_values_helper sklearn/linear_model/tests/test_ridge.py::test_errors_and_values_svd_helper sklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_no_support_multilabel sklearn/linear_model/tests/test_ridge.py::test_dtype_match sklearn/linear_model/tests/test_ridge.py::test_dtype_match_cholesky\n",
      "\n",
      "Exit: 4\n",
      "o collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_ridgecv_sample_weight\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_sample_weights_greater_than_1d\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_sparse_design_with_sample_weights\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_solver_not_supported\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_sparse_cg_max_iter\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_n_iter\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_ridge_fit_intercept_sparse\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_errors_and_values_helper\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_errors_and_values_svd_helper\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_no_support_multilabel\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_dtype_match\n",
      "\u001b[0m\n",
      "\u001b[31mERROR: found no collectors for /workspace/sklearn/linear_model/tests/test_ridge.py::test_dtype_match_cholesky\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "‚ö†Ô∏è Tests had issues\n"
     ]
    }
   ],
   "source": [
    "print(\"üß™ Running existing tests...\\n\")\n",
    "\n",
    "# Get tests from metadata\n",
    "fail_to_pass = sample.get('metadata', {}).get('FAIL_TO_PASS', '[]')\n",
    "pass_to_pass = sample.get('metadata', {}).get('PASS_TO_PASS', '[]')\n",
    "\n",
    "print(f\"  FAIL_TO_PASS: {fail_to_pass}\")\n",
    "print(f\"  PASS_TO_PASS: {pass_to_pass}\\n\")\n",
    "\n",
    "# Parse test lists\n",
    "try:\n",
    "    f2p = ast.literal_eval(fail_to_pass) if isinstance(fail_to_pass, str) else fail_to_pass\n",
    "    p2p = ast.literal_eval(pass_to_pass) if isinstance(pass_to_pass, str) else pass_to_pass\n",
    "except:\n",
    "    f2p, p2p = [], []\n",
    "\n",
    "all_tests = f2p + p2p\n",
    "\n",
    "# Use the proper function from test_patch_singularity\n",
    "test_result = run_tests_in_singularity(\n",
    "    repo_path=Path(repo_path),\n",
    "    tests=all_tests,\n",
    "    image_path=CONTAINER_IMAGE_PATH\n",
    ")\n",
    "\n",
    "print(f\"Exit: {test_result['returncode']}\")\n",
    "print((test_result['stdout'] + test_result['stderr'])[-1500:])\n",
    "print(f\"\\n{'‚úì' if test_result['returncode'] == 0 else '‚ö†Ô∏è'} Tests {'passed' if test_result['returncode'] == 0 else 'had issues'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7: Analyze Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing patch...\n",
      "‚úì Files: 1\n",
      "  Module: sklearn.linear_model.ridge\n",
      "  Functions: ['__init__']\n",
      "  Classes: ['RidgeClassifierCV']\n",
      "  Lines: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Analyzing patch...\")\n",
    "\n",
    "patch_analyzer = PatchAnalyzer()\n",
    "modified_files = filter_paths_to_py(list(parse_unified_diff(sample['patch']).keys()))\n",
    "\n",
    "if modified_files:\n",
    "    first_file_path = modified_files[0]  # e.g., \"src/_pytest/logging.py\"\n",
    "    first_file = Path(repo_path) / first_file_path\n",
    "    patched_code = first_file.read_text(encoding='utf-8')\n",
    "    \n",
    "    # Pass file_path to parse_patch for proper module detection\n",
    "    patch_analysis = patch_analyzer.parse_patch(sample['patch'], patched_code, file_path=first_file_path)\n",
    "    \n",
    "    print(f\"‚úì Files: {len(modified_files)}\")\n",
    "    print(f\"  Module: {patch_analysis.module_path}\")\n",
    "    print(f\"  Functions: {patch_analysis.changed_functions}\")\n",
    "    if patch_analysis.class_context:\n",
    "        print(f\"  Classes: {list(patch_analysis.class_context.values())}\")\n",
    "    print(f\"  Lines: {len(patch_analysis.all_changed_lines)}\")\n",
    "else:\n",
    "    patch_analysis = None\n",
    "    patched_code = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 8: Generate Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Generating tests...\n",
      "‚úì Generated 1 tests\n",
      "\n",
      "# Auto-generated change-aware fuzzing tests for patch validation\n",
      "import pytest\n",
      "from hypothesis import given, strategies as st, settings\n",
      "from hypothesis import assume\n",
      "import sys\n",
      "from pathlib import Path\n",
      "\n",
      "# Import from patched module: sklearn.linear_model.ridge\n",
      "from sklearn.linear_model.ridge import RidgeClassifierCV\n",
      "\n",
      "def test___init___exists():\n",
      "    \"\"\"Verify RidgeClassifierCV.__init__ exists and is callable\"\"\"\n",
      "    assert hasattr(RidgeClassifierCV, '__init__'), 'RidgeClassifierCV should have __init__ method'\n",
      "    # Note: Full property-based testing of methods requires instance creation\n",
      "    # whic...\n"
     ]
    }
   ],
   "source": [
    "if patch_analysis and patch_analysis.changed_functions:\n",
    "    print(\"üß¨ Generating tests...\")\n",
    "    \n",
    "    test_generator = HypothesisTestGenerator()\n",
    "    test_code = test_generator.generate_tests(patch_analysis, patched_code)\n",
    "    test_count = test_code.count('def test_')\n",
    "    \n",
    "    print(f\"‚úì Generated {test_count} tests\")\n",
    "    print(f\"\\n{test_code[:600]}...\")\n",
    "else:\n",
    "    test_code = None\n",
    "    test_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 9: Execute Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê≥ Executing change-aware fuzzing tests...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå FAILED (6.8s)\n",
      "\n",
      "=== FULL OUTPUT ===\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.11.14, pytest-9.0.1, pluggy-1.6.0 -- /usr/local/bin/python3.11\n",
      "cachedir: .pytest_cache\n",
      "hypothesis profile 'default'\n",
      "rootdir: /workspace\n",
      "configfile: setup.cfg\n",
      "plugins: hypothesis-6.148.1, cov-7.0.0, timeout-2.4.0, xdist-3.8.0\n",
      "timeout: 120.0s\n",
      "timeout method: signal\n",
      "timeout func_only: False\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 2 errors\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m__________________ ERROR collecting test_fuzzing_generated.py __________________\u001b[0m\n",
      "\u001b[31mImportError while importing test module '/workspace/test_fuzzing_generated.py'.\n",
      "Hint: make sure your test modules/packages have valid Python names.\n",
      "Traceback:\n",
      "\u001b[1m\u001b[31msklearn/__check_build/__init__.py\u001b[0m:44: in <module>\n",
      "    \u001b[0m\u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96m_check_build\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m check_build  \u001b[90m# noqa\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   ModuleNotFoundError: No module named 'sklearn.__check_build._check_build'\u001b[0m\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[1m\u001b[31m/usr/local/lib/python3.11/importlib/__init__.py\u001b[0m:126: in import_module\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _bootstrap._gcd_import(name[level:], package, level)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mtest_fuzzing_generated.py\u001b[0m:9: in <module>\n",
      "    \u001b[0m\u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msklearn\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mlinear_model\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mridge\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m RidgeClassifierCV\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31msklearn/__init__.py\u001b[0m:133: in <module>\n",
      "    \u001b[0m\u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m __check_build\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31msklearn/__check_build/__init__.py\u001b[0m:46: in <module>\n",
      "    \u001b[0mraise_build_error(e)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31msklearn/__check_build/__init__.py\u001b[0m:31: in raise_build_error\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mImportError\u001b[39;49;00m(\u001b[33m\"\"\"\u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   ImportError: No module named 'sklearn.__check_build._check_build'\u001b[0m\n",
      "\u001b[1m\u001b[31mE   ___________________________________________________________________________\u001b[0m\n",
      "\u001b[1m\u001b[31mE   Contents of /workspace/sklearn/__check_build:\u001b[0m\n",
      "\u001b[1m\u001b[31mE   __init__.py               __pycache__               _check_build.pyx\u001b[0m\n",
      "\u001b[1m\u001b[31mE   setup.py\u001b[0m\n",
      "\u001b[1m\u001b[31mE   ___________________________________________________________________________\u001b[0m\n",
      "\u001b[1m\u001b[31mE   It seems that scikit-learn has not been built correctly.\u001b[0m\n",
      "\u001b[1m\u001b[31mE   \u001b[0m\n",
      "\u001b[1m\u001b[31mE   If you have installed scikit-learn from source, please do not forget\u001b[0m\n",
      "\u001b[1m\u001b[31mE   to build the package before using it: run `python setup.py install` or\u001b[0m\n",
      "\u001b[1m\u001b[31mE   `make` in the source directory.\u001b[0m\n",
      "\u001b[1m\u001b[31mE   \u001b[0m\n",
      "\u001b[1m\u001b[31mE   If you have used an installer, please check that it is suited for your\u001b[0m\n",
      "\u001b[1m\u001b[31mE   Python version, your operating system and your platform.\u001b[0m\u001b[0m\n",
      "\u001b[31m\u001b[1m__________________ ERROR collecting test_fuzzing_generated.py __________________\u001b[0m\n",
      "\u001b[31mImportError while importing test module '/workspace/test_fuzzing_generated.py'.\n",
      "Hint: make sure your test modules/packages have valid Python names.\n",
      "Traceback:\n",
      "\u001b[1m\u001b[31msklearn/__check_build/__init__.py\u001b[0m:44: in <module>\n",
      "    \u001b[0m\u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96m_check_build\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m check_build  \u001b[90m# noqa\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   ModuleNotFoundError: No module named 'sklearn.__check_build._check_build'\u001b[0m\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[1m\u001b[31m/usr/local/lib/python3.11/importlib/__init__.py\u001b[0m:126: in import_module\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _bootstrap._gcd_import(name[level:], package, level)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mtest_fuzzing_generated.py\u001b[0m:9: in <module>\n",
      "    \u001b[0m\u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96msklearn\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mlinear_model\u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[04m\u001b[96mridge\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m RidgeClassifierCV\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31msklearn/__init__.py\u001b[0m:133: in <module>\n",
      "    \u001b[0m\u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96m.\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mimport\u001b[39;49;00m __check_build\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31msklearn/__check_build/__init__.py\u001b[0m:46: in <module>\n",
      "    \u001b[0mraise_build_error(e)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31msklearn/__check_build/__init__.py\u001b[0m:31: in raise_build_error\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m \u001b[96mImportError\u001b[39;49;00m(\u001b[33m\"\"\"\u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   ImportError: No module named 'sklearn.__check_build._check_build'\u001b[0m\n",
      "\u001b[1m\u001b[31mE   ___________________________________________________________________________\u001b[0m\n",
      "\u001b[1m\u001b[31mE   Contents of /workspace/sklearn/__check_build:\u001b[0m\n",
      "\u001b[1m\u001b[31mE   __init__.py               __pycache__               _check_build.pyx\u001b[0m\n",
      "\u001b[1m\u001b[31mE   setup.py\u001b[0m\n",
      "\u001b[1m\u001b[31mE   ___________________________________________________________________________\u001b[0m\n",
      "\u001b[1m\u001b[31mE   It seems that scikit-learn has not been built correctly.\u001b[0m\n",
      "\u001b[1m\u001b[31mE   \u001b[0m\n",
      "\u001b[1m\u001b[31mE   If you have installed scikit-learn from source, please do not forget\u001b[0m\n",
      "\u001b[1m\u001b[31mE   to build the package before using it: run `python setup.py install` or\u001b[0m\n",
      "\u001b[1m\u001b[31mE   `make` in the source directory.\u001b[0m\n",
      "\u001b[1m\u001b[31mE   \u001b[0m\n",
      "\u001b[1m\u001b[31mE   If you have used an installer, please check that it is suited for your\u001b[0m\n",
      "\u001b[1m\u001b[31mE   Python version, your operating system and your platform.\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m test_fuzzing_generated.py\n",
      "\u001b[31mERROR\u001b[0m test_fuzzing_generated.py\n",
      "!!!!!!!!!!!!!!!!!!! Interrupted: 2 errors during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m========================= \u001b[33m1 warning\u001b[0m, \u001b[31m\u001b[1m2 errors\u001b[0m\u001b[31m in 3.06s\u001b[0m\u001b[31m =========================\u001b[0m\n",
      "\n",
      "WARNING: passwd file doesn't exist in container, not updating\n",
      "WARNING: group file doesn't exist in container, not updating\n",
      "\n",
      "=== END OUTPUT ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if test_code:\n",
    "    print(\"üê≥ Executing change-aware fuzzing tests...\\n\")\n",
    "    \n",
    "    executor = SingularityTestExecutor(CONTAINER_IMAGE_PATH, timeout=120)\n",
    "    start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Pass module_name from patch_analysis for proper coverage tracking\n",
    "        module_name = patch_analysis.module_path if patch_analysis else None\n",
    "        \n",
    "        success, output, coverage_data = executor.run_tests_with_existing_infrastructure(\n",
    "            Path(repo_path), \n",
    "            test_code,\n",
    "            module_name=module_name\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        print(f\"{'‚úì PASSED' if success else '‚ùå FAILED'} ({elapsed:.1f}s)\\n\")\n",
    "        \n",
    "        # Show full output to see actual test results\n",
    "        print(\"=== FULL OUTPUT ===\")\n",
    "        print(output)\n",
    "        print(\"=== END OUTPUT ===\\n\")\n",
    "        \n",
    "        # Also show just the test summary\n",
    "        if \"passed\" in output or \"PASSED\" in output:\n",
    "            lines = output.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if 'test_' in line or 'passed' in line.lower() or 'failed' in line.lower():\n",
    "                    print(line)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        success = False\n",
    "        coverage_data = {}\n",
    "else:\n",
    "    success = True\n",
    "    coverage_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 10: Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patch_analysis and coverage_data:\n",
    "    # Check if coverage was intentionally skipped\n",
    "    if coverage_data.get('_coverage_skipped'):\n",
    "        print(f\"‚ÑπÔ∏è  Coverage skipped: {coverage_data.get('_skip_reason', 'N/A')}\")\n",
    "        coverage_result = {'overall_coverage': None, 'total_changed_lines': 0, 'total_covered_lines': 0, 'skipped': True}\n",
    "    else:\n",
    "        coverage_analyzer = CoverageAnalyzer()\n",
    "        coverage_result = coverage_analyzer.calculate_changed_line_coverage(\n",
    "            coverage_data, patch_analysis.changed_lines, patch_analysis.all_changed_lines\n",
    "        )\n",
    "        print(f\"üìä Coverage: {coverage_result['overall_coverage']:.1%}\")\n",
    "        print(f\"   {coverage_result['total_covered_lines']}/{coverage_result['total_changed_lines']} lines\")\n",
    "else:\n",
    "    coverage_result = {'overall_coverage': 0.0, 'total_changed_lines': 0, 'total_covered_lines': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 11: Verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VERDICT\n",
      "================================================================================\n",
      "REJECT: Tests failed\n",
      "\n",
      "SQI: 61.54% | Tests: 1 | Coverage: 0.0%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "sqi_score = sqi_data.get('SQI', 0) / 100.0\n",
    "coverage_score = coverage_result.get('overall_coverage', 0.0)\n",
    "coverage_skipped = coverage_result.get('skipped', False)\n",
    "\n",
    "if sqi_score < 0.5:\n",
    "    verdict = 'REJECT'\n",
    "    reason = f'Poor SQI ({sqi_score:.2f})'\n",
    "elif not success:\n",
    "    verdict = 'REJECT'\n",
    "    reason = 'Tests failed'\n",
    "elif coverage_skipped:\n",
    "    verdict = 'ACCEPT' if test_count > 0 else 'WARNING'\n",
    "    reason = 'Coverage N/A (pytest internal module)' if test_count > 0 else 'No tests generated'\n",
    "elif coverage_score is not None and coverage_score < 0.5:\n",
    "    verdict = 'WARNING'\n",
    "    reason = f'Low coverage ({coverage_score:.1%})'\n",
    "else:\n",
    "    verdict = 'ACCEPT'\n",
    "    reason = 'All checks passed'\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERDICT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{verdict}: {reason}\")\n",
    "if coverage_score is not None:\n",
    "    print(f\"\\nSQI: {sqi_score:.2%} | Tests: {test_count} | Coverage: {coverage_score:.1%}\")\n",
    "else:\n",
    "    print(f\"\\nSQI: {sqi_score:.2%} | Tests: {test_count} | Coverage: N/A (pytest internal)\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
